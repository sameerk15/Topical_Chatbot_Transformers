{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport string, os \nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:15:57.932744Z","iopub.execute_input":"2022-04-09T05:15:57.933150Z","iopub.status.idle":"2022-04-09T05:16:02.673511Z","shell.execute_reply.started":"2022-04-09T05:15:57.933041Z","shell.execute_reply":"2022-04-09T05:16:02.672376Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:16:12.494809Z","iopub.execute_input":"2022-04-09T05:16:12.495157Z","iopub.status.idle":"2022-04-09T05:16:12.507841Z","shell.execute_reply.started":"2022-04-09T05:16:12.495120Z","shell.execute_reply":"2022-04-09T05:16:12.507155Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 200  # Number of epochs to train for.\nlatent_dim = 512  # Latent dimensionality of the encoding space.\nnum_samples = 50000","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:16:18.587437Z","iopub.execute_input":"2022-04-09T05:16:18.587791Z","iopub.status.idle":"2022-04-09T05:16:18.592127Z","shell.execute_reply.started":"2022-04-09T05:16:18.587759Z","shell.execute_reply":"2022-04-09T05:16:18.591184Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# reading dataset\ndf = pd.read_csv('../input/chatbot-dataset-topical-chat/topical_chat.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:16:22.041465Z","iopub.execute_input":"2022-04-09T05:16:22.041957Z","iopub.status.idle":"2022-04-09T05:16:22.685115Z","shell.execute_reply.started":"2022-04-09T05:16:22.041922Z","shell.execute_reply":"2022-04-09T05:16:22.684204Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# basic preprocessing\ndef process(text):\n    text = text.lower().replace('\\n', ' ').replace('-', ' ').replace(':', ' ').replace(',', '') \\\n          .replace('\"', ' ').replace(\".\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\";\", \" \").replace(\":\", \" \")\n\n    text = \"\".join(v for v in text if v not in string.punctuation).lower()\n    #text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n\n    text = \" \".join(text.split())\n    #text+=\"<eos>\"\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:16:25.705125Z","iopub.execute_input":"2022-04-09T05:16:25.705459Z","iopub.status.idle":"2022-04-09T05:16:25.711634Z","shell.execute_reply.started":"2022-04-09T05:16:25.705431Z","shell.execute_reply":"2022-04-09T05:16:25.710488Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.message = df.message.apply(process)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:16:28.431360Z","iopub.execute_input":"2022-04-09T05:16:28.431694Z","iopub.status.idle":"2022-04-09T05:16:31.996043Z","shell.execute_reply.started":"2022-04-09T05:16:28.431664Z","shell.execute_reply":"2022-04-09T05:16:31.995152Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:16:34.794213Z","iopub.execute_input":"2022-04-09T05:16:34.794527Z","iopub.status.idle":"2022-04-09T05:16:34.806813Z","shell.execute_reply.started":"2022-04-09T05:16:34.794501Z","shell.execute_reply":"2022-04-09T05:16:34.806147Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_words_set = set()\ntarget_words_set = set()\n\nfor conversation_index in tqdm(range(df.shape[0])):\n    \n    if conversation_index == 0:\n        continue\n        \n    input_text = df.iloc[conversation_index - 1]\n    target_text = df.iloc[conversation_index]\n    \n    if input_text.conversation_id == target_text.conversation_id:\n        \n        input_text = input_text.message\n        target_text = target_text.message\n        \n        if len(input_text.split()) > 2 and \\\n            len(target_text.split()) > 0 and \\\n            len(input_text.split()) < 30 and \\\n            len(target_text.split()) < 10 and \\\n            input_text and \\\n            target_text:\n            \n            target_text = \"bos \" + target_text + \" eos\"\n                \n            input_texts.append(input_text)\n            target_texts.append(target_text)\n            \n            for word in input_text.split():\n                if word not in input_words_set:\n                    input_words_set.add(word)\n            for word in target_text.split():\n                if word not in target_words_set:\n                    target_words_set.add(word)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:16:38.952337Z","iopub.execute_input":"2022-04-09T05:16:38.952697Z","iopub.status.idle":"2022-04-09T05:17:33.877980Z","shell.execute_reply.started":"2022-04-09T05:16:38.952667Z","shell.execute_reply":"2022-04-09T05:17:33.877204Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"input_texts","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:18:28.858974Z","iopub.execute_input":"2022-04-09T05:18:28.859490Z","iopub.status.idle":"2022-04-09T05:18:28.885487Z","shell.execute_reply.started":"2022-04-09T05:18:28.859455Z","shell.execute_reply":"2022-04-09T05:18:28.884443Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"target_texts","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:19:12.718313Z","iopub.execute_input":"2022-04-09T05:19:12.718648Z","iopub.status.idle":"2022-04-09T05:19:12.741913Z","shell.execute_reply.started":"2022-04-09T05:19:12.718618Z","shell.execute_reply":"2022-04-09T05:19:12.740961Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\n\nimport os\nimport re\nimport numpy as np\nimport pandas as pd\nimport math\n\nimport matplotlib.pyplot as plt\nMAX_SENTENCE_LENGTH = 60","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:28:35.706350Z","iopub.execute_input":"2022-04-09T05:28:35.706669Z","iopub.status.idle":"2022-04-09T05:28:35.712058Z","shell.execute_reply.started":"2022-04-09T05:28:35.706640Z","shell.execute_reply":"2022-04-09T05:28:35.711078Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n    input_texts + target_texts, target_vocab_size=2**13)\n\nSTART_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n\nVOCAB_SIZE = tokenizer.vocab_size + 2","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:25:24.290868Z","iopub.execute_input":"2022-04-09T05:25:24.291225Z","iopub.status.idle":"2022-04-09T05:25:50.163290Z","shell.execute_reply.started":"2022-04-09T05:25:24.291192Z","shell.execute_reply":"2022-04-09T05:25:50.162510Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_filter(input_texts, target_texts):\n  tokenized_inputs, tokenized_outputs = [], []\n  \n  for (sentence1, sentence2) in zip(input_texts, target_texts):\n    # tokenize sentence\n    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n    # check tokenized sentence max length\n    if len(sentence1) <= MAX_SENTENCE_LENGTH and len(sentence2) <= MAX_SENTENCE_LENGTH:\n      tokenized_inputs.append(sentence1)\n      tokenized_outputs.append(sentence2)\n  \n  # pad tokenized sentences\n  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n      tokenized_inputs, maxlen=MAX_SENTENCE_LENGTH, padding='post')\n  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n      tokenized_outputs, maxlen=MAX_SENTENCE_LENGTH, padding='post')\n  \n  return tokenized_inputs, tokenized_outputs\n\n\ninput_texts, target_texts = tokenize_and_filter(input_texts, target_texts)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:33:13.136396Z","iopub.execute_input":"2022-04-09T05:33:13.136750Z","iopub.status.idle":"2022-04-09T05:33:15.007876Z","shell.execute_reply.started":"2022-04-09T05:33:13.136719Z","shell.execute_reply":"2022-04-09T05:33:15.006961Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print('Vocab size: {}'.format(VOCAB_SIZE))\nprint('Number of samples: {}'.format(len(input_texts)))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:33:54.681405Z","iopub.execute_input":"2022-04-09T05:33:54.681730Z","iopub.status.idle":"2022-04-09T05:33:54.687389Z","shell.execute_reply.started":"2022-04-09T05:33:54.681701Z","shell.execute_reply":"2022-04-09T05:33:54.686421Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nBUFFER_SIZE = 20000\n\ndataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'inputs': input_texts,\n        'dec_inputs': target_texts[:, :-1]\n    },\n    {\n        'outputs': target_texts[:, 1:]\n    },\n))\n\ndataset = dataset.cache()\ndataset = dataset.shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE)\ndataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:34:53.117922Z","iopub.execute_input":"2022-04-09T05:34:53.118286Z","iopub.status.idle":"2022-04-09T05:34:55.096452Z","shell.execute_reply.started":"2022-04-09T05:34:53.118256Z","shell.execute_reply":"2022-04-09T05:34:55.095589Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def scaled_dot_product_attention(query, key, value, mask):\n  \"\"\"Calculate the attention weights. \"\"\"\n  matmul_qk = tf.matmul(query, key, transpose_b=True)\n\n  # scale matmul_qk\n  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n  logits = matmul_qk / tf.math.sqrt(depth)\n\n  # add the mask to zero out padding tokens\n  if mask is not None:\n    logits += (mask * -1e9)\n\n  # softmax is normalized on the last axis (seq_len_k)\n  attention_weights = tf.nn.softmax(logits, axis=-1)\n\n  output = tf.matmul(attention_weights, value)\n\n  return output","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:35:10.904462Z","iopub.execute_input":"2022-04-09T05:35:10.904825Z","iopub.status.idle":"2022-04-09T05:35:10.911940Z","shell.execute_reply.started":"2022-04-09T05:35:10.904794Z","shell.execute_reply":"2022-04-09T05:35:10.910767Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n\n  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n    super(MultiHeadAttention, self).__init__(name=name)\n    self.num_heads = num_heads\n    self.d_model = d_model\n\n    assert d_model % self.num_heads == 0\n\n    self.depth = d_model // self.num_heads\n\n    self.query_dense = tf.keras.layers.Dense(units=d_model)\n    self.key_dense = tf.keras.layers.Dense(units=d_model)\n    self.value_dense = tf.keras.layers.Dense(units=d_model)\n\n    self.dense = tf.keras.layers.Dense(units=d_model)\n\n  def split_heads(self, inputs, batch_size):\n    inputs = tf.reshape(\n        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n\n  def call(self, inputs):\n    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n        'value'], inputs['mask']\n    batch_size = tf.shape(query)[0]\n\n    # linear layers\n    query = self.query_dense(query)\n    key = self.key_dense(key)\n    value = self.value_dense(value)\n\n    # split heads\n    query = self.split_heads(query, batch_size)\n    key = self.split_heads(key, batch_size)\n    value = self.split_heads(value, batch_size)\n\n    # scaled dot-product attention\n    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n\n    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n    # concatenation of heads\n    concat_attention = tf.reshape(scaled_attention,\n                                  (batch_size, -1, self.d_model))\n\n    # final linear layer\n    outputs = self.dense(concat_attention)\n\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:35:35.261218Z","iopub.execute_input":"2022-04-09T05:35:35.261556Z","iopub.status.idle":"2022-04-09T05:35:35.273197Z","shell.execute_reply.started":"2022-04-09T05:35:35.261514Z","shell.execute_reply":"2022-04-09T05:35:35.272221Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def create_padding_mask(x):\n  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n  # (batch_size, 1, 1, sequence length)\n  return mask[:, tf.newaxis, tf.newaxis, :]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:35:50.723661Z","iopub.execute_input":"2022-04-09T05:35:50.724070Z","iopub.status.idle":"2022-04-09T05:35:50.728740Z","shell.execute_reply.started":"2022-04-09T05:35:50.724022Z","shell.execute_reply":"2022-04-09T05:35:50.727671Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:36:04.144047Z","iopub.execute_input":"2022-04-09T05:36:04.144383Z","iopub.status.idle":"2022-04-09T05:36:04.447169Z","shell.execute_reply.started":"2022-04-09T05:36:04.144352Z","shell.execute_reply":"2022-04-09T05:36:04.446053Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def create_look_ahead_mask(x):\n  seq_len = tf.shape(x)[1]\n  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n  padding_mask = create_padding_mask(x)\n  return tf.maximum(look_ahead_mask, padding_mask)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:36:15.396811Z","iopub.execute_input":"2022-04-09T05:36:15.397144Z","iopub.status.idle":"2022-04-09T05:36:15.403989Z","shell.execute_reply.started":"2022-04-09T05:36:15.397109Z","shell.execute_reply":"2022-04-09T05:36:15.401621Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:36:25.047521Z","iopub.execute_input":"2022-04-09T05:36:25.047854Z","iopub.status.idle":"2022-04-09T05:36:25.077936Z","shell.execute_reply.started":"2022-04-09T05:36:25.047825Z","shell.execute_reply":"2022-04-09T05:36:25.077077Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(tf.keras.layers.Layer):\n\n  def __init__(self, position, d_model):\n    super(PositionalEncoding, self).__init__()\n    self.pos_encoding = self.positional_encoding(position, d_model)\n\n  def get_angles(self, position, i, d_model):\n    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n    return position * angles\n\n  def positional_encoding(self, position, d_model):\n    angle_rads = self.get_angles(\n        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n        d_model=d_model)\n    # apply sin to even index in the array\n    sines = tf.math.sin(angle_rads[:, 0::2])\n    # apply cos to odd index in the array\n    cosines = tf.math.cos(angle_rads[:, 1::2])\n\n    pos_encoding = tf.concat([sines, cosines], axis=-1)\n    pos_encoding = pos_encoding[tf.newaxis, ...]\n    return tf.cast(pos_encoding, tf.float32)\n\n  def call(self, inputs):\n    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:36:39.595783Z","iopub.execute_input":"2022-04-09T05:36:39.596115Z","iopub.status.idle":"2022-04-09T05:36:39.605339Z","shell.execute_reply.started":"2022-04-09T05:36:39.596068Z","shell.execute_reply":"2022-04-09T05:36:39.604271Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"sample_pos_encoding = PositionalEncoding(50, 512)\n\nplt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\nplt.xlabel('Depth')\nplt.xlim((0, 512))\nplt.ylabel('Position')\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:36:53.833940Z","iopub.execute_input":"2022-04-09T05:36:53.834320Z","iopub.status.idle":"2022-04-09T05:36:54.090900Z","shell.execute_reply.started":"2022-04-09T05:36:53.834289Z","shell.execute_reply":"2022-04-09T05:36:54.090028Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n  attention = MultiHeadAttention(\n      d_model, num_heads, name=\"attention\")({\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': padding_mask\n      })\n  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n  attention = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(inputs + attention)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention + outputs)\n\n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:37:07.815293Z","iopub.execute_input":"2022-04-09T05:37:07.815617Z","iopub.status.idle":"2022-04-09T05:37:07.823467Z","shell.execute_reply.started":"2022-04-09T05:37:07.815588Z","shell.execute_reply":"2022-04-09T05:37:07.822323Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"sample_encoder_layer = encoder_layer(\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_encoder_layer\")\n\ntf.keras.utils.plot_model(\n    sample_encoder_layer, to_file='encoder_layer.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:37:18.210948Z","iopub.execute_input":"2022-04-09T05:37:18.211337Z","iopub.status.idle":"2022-04-09T05:37:19.216967Z","shell.execute_reply.started":"2022-04-09T05:37:18.211305Z","shell.execute_reply":"2022-04-09T05:37:19.216068Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def encoder(vocab_size,\n            num_layers,\n            units,\n            d_model,\n            num_heads,\n            dropout,\n            name=\"encoder\"):\n  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n  for i in range(num_layers):\n    outputs = encoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name=\"encoder_layer_{}\".format(i),\n    )([outputs, padding_mask])\n\n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:37:34.385355Z","iopub.execute_input":"2022-04-09T05:37:34.385817Z","iopub.status.idle":"2022-04-09T05:37:34.400589Z","shell.execute_reply.started":"2022-04-09T05:37:34.385776Z","shell.execute_reply":"2022-04-09T05:37:34.399562Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"sample_encoder = encoder(\n    vocab_size=8515,\n    num_layers=2,\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_encoder\")\n\ntf.keras.utils.plot_model(\n   sample_encoder, to_file='encoder.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:38:08.232084Z","iopub.execute_input":"2022-04-09T05:38:08.232446Z","iopub.status.idle":"2022-04-09T05:38:08.960112Z","shell.execute_reply.started":"2022-04-09T05:38:08.232418Z","shell.execute_reply":"2022-04-09T05:38:08.959157Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n  look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name=\"look_ahead_mask\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n  attention1 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_1\")(inputs={\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': look_ahead_mask\n      })\n  attention1 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention1 + inputs)\n\n  attention2 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_2\")(inputs={\n          'query': attention1,\n          'key': enc_outputs,\n          'value': enc_outputs,\n          'mask': padding_mask\n      })\n  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n  attention2 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention2 + attention1)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(outputs + attention2)\n\n  return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:38:39.366584Z","iopub.execute_input":"2022-04-09T05:38:39.366930Z","iopub.status.idle":"2022-04-09T05:38:39.377981Z","shell.execute_reply.started":"2022-04-09T05:38:39.366896Z","shell.execute_reply":"2022-04-09T05:38:39.377182Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"sample_decoder_layer = decoder_layer(\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_decoder_layer\")\n\ntf.keras.utils.plot_model(\n    sample_decoder_layer, to_file='decoder_layer.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:38:54.097152Z","iopub.execute_input":"2022-04-09T05:38:54.097485Z","iopub.status.idle":"2022-04-09T05:38:54.603473Z","shell.execute_reply.started":"2022-04-09T05:38:54.097457Z","shell.execute_reply":"2022-04-09T05:38:54.602537Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def decoder(vocab_size,\n            num_layers,\n            units,\n            d_model,\n            num_heads,\n            dropout,\n            name='decoder'):\n  inputs = tf.keras.Input(shape=(None,), name='inputs')\n  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n  look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name='look_ahead_mask')\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n  \n  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n  for i in range(num_layers):\n    outputs = decoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name='decoder_layer_{}'.format(i),\n    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n\n  return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:39:27.347843Z","iopub.execute_input":"2022-04-09T05:39:27.348195Z","iopub.status.idle":"2022-04-09T05:39:27.357685Z","shell.execute_reply.started":"2022-04-09T05:39:27.348163Z","shell.execute_reply":"2022-04-09T05:39:27.356675Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"sample_decoder = decoder(\n    vocab_size=8515,\n    num_layers=2,\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_decoder\")\n\ntf.keras.utils.plot_model(\n    sample_decoder, to_file='decoder.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:40:01.400807Z","iopub.execute_input":"2022-04-09T05:40:01.401147Z","iopub.status.idle":"2022-04-09T05:40:02.467120Z","shell.execute_reply.started":"2022-04-09T05:40:01.401112Z","shell.execute_reply":"2022-04-09T05:40:02.466027Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def transformer(vocab_size,\n                num_layers,\n                units,\n                d_model,\n                num_heads,\n                dropout,\n                name=\"transformer\"):\n  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n\n  enc_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='enc_padding_mask')(inputs)\n  # mask the future tokens for decoder inputs at the 1st attention block\n  look_ahead_mask = tf.keras.layers.Lambda(\n      create_look_ahead_mask,\n      output_shape=(1, None, None),\n      name='look_ahead_mask')(dec_inputs)\n  # mask the encoder outputs for the 2nd attention block\n  dec_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='dec_padding_mask')(inputs)\n\n  enc_outputs = encoder(\n      vocab_size=vocab_size,\n      num_layers=num_layers,\n      units=units,\n      d_model=d_model,\n      num_heads=num_heads,\n      dropout=dropout,\n  )(inputs=[inputs, enc_padding_mask])\n\n  dec_outputs = decoder(\n      vocab_size=vocab_size,\n      num_layers=num_layers,\n      units=units,\n      d_model=d_model,\n      num_heads=num_heads,\n      dropout=dropout,\n  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n\n  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n\n  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:40:24.727232Z","iopub.execute_input":"2022-04-09T05:40:24.727567Z","iopub.status.idle":"2022-04-09T05:40:24.737268Z","shell.execute_reply.started":"2022-04-09T05:40:24.727537Z","shell.execute_reply":"2022-04-09T05:40:24.736322Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"sample_transformer = transformer(\n    vocab_size=8515,\n    num_layers=2,\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_transformer\")\n\ntf.keras.utils.plot_model(\n    sample_transformer, to_file='transformer.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:40:41.934639Z","iopub.execute_input":"2022-04-09T05:40:41.934964Z","iopub.status.idle":"2022-04-09T05:40:44.319124Z","shell.execute_reply.started":"2022-04-09T05:40:41.934934Z","shell.execute_reply":"2022-04-09T05:40:44.318089Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\n# Hyper-parameters\nNUM_LAYERS = 2\nD_MODEL = 256\nNUM_HEADS = 8\nUNITS = 512\nDROPOUT = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:40:58.857017Z","iopub.execute_input":"2022-04-09T05:40:58.857376Z","iopub.status.idle":"2022-04-09T05:40:58.865943Z","shell.execute_reply.started":"2022-04-09T05:40:58.857346Z","shell.execute_reply":"2022-04-09T05:40:58.865191Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = transformer(\n    vocab_size=VOCAB_SIZE,\n    num_layers=NUM_LAYERS,\n    units=UNITS,\n    d_model=D_MODEL,\n    num_heads=NUM_HEADS,\n    dropout=DROPOUT)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:41:09.222964Z","iopub.execute_input":"2022-04-09T05:41:09.223320Z","iopub.status.idle":"2022-04-09T05:41:11.248562Z","shell.execute_reply.started":"2022-04-09T05:41:09.223290Z","shell.execute_reply":"2022-04-09T05:41:11.247756Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def loss_function(y_true, y_pred):\n  y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n  \n  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n      from_logits=True, reduction='none')(y_true, y_pred)\n\n  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n  loss = tf.multiply(loss, mask)\n\n  return tf.reduce_mean(loss)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:41:21.775358Z","iopub.execute_input":"2022-04-09T05:41:21.775676Z","iopub.status.idle":"2022-04-09T05:41:21.783254Z","shell.execute_reply.started":"2022-04-09T05:41:21.775648Z","shell.execute_reply":"2022-04-09T05:41:21.782148Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n\n  def __init__(self, d_model, warmup_steps=2000):\n    super(CustomSchedule, self).__init__()\n\n    self.d_model = d_model\n    self.d_model = tf.cast(self.d_model, tf.float32)\n\n    self.warmup_steps = warmup_steps\n\n  def __call__(self, step):\n    arg1 = tf.math.rsqrt(step)\n    arg2 = step * (self.warmup_steps**-1.5)\n\n    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:41:34.634781Z","iopub.execute_input":"2022-04-09T05:41:34.635184Z","iopub.status.idle":"2022-04-09T05:41:34.642198Z","shell.execute_reply.started":"2022-04-09T05:41:34.635152Z","shell.execute_reply":"2022-04-09T05:41:34.641049Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"sample_learning_rate = CustomSchedule(d_model=256)\n\nplt.plot(sample_learning_rate(tf.range(3768, dtype=tf.float32)))\nplt.ylabel(\"Learning Rate\")\nplt.xlabel(\"Train Step\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:41:48.972202Z","iopub.execute_input":"2022-04-09T05:41:48.972536Z","iopub.status.idle":"2022-04-09T05:41:49.130477Z","shell.execute_reply.started":"2022-04-09T05:41:48.972507Z","shell.execute_reply":"2022-04-09T05:41:49.129768Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def perplexity(real, pred):\n    \"\"\"\n    This function returns the perplexity for model's predictions on a batch \n    of data in comparison with the real outputs at a timestep.\n    Arguments:\n        real: real output, a Tensorflow tensor with a shape \n              of: (batch_size, max_seq_length)\n        pred: model's predictions at a certain timestep, a Tensorflow tensor \n              with a shape of: (batch_size, max_seq_length)\n    Returns:\n        A Tensorflow tensor with the perplexity.\n    \"\"\"\n    real = tf.reshape(real, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n    loss = loss_function(real, pred)\n    \n    return tf.cast(tf.pow(math.e, loss), dtype=tf.keras.backend.floatx())","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:42:19.054118Z","iopub.execute_input":"2022-04-09T05:42:19.054458Z","iopub.status.idle":"2022-04-09T05:42:19.059680Z","shell.execute_reply.started":"2022-04-09T05:42:19.054428Z","shell.execute_reply":"2022-04-09T05:42:19.058749Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def accuracy(y_true, y_pred):\n  # ensure labels have shape (batch_size, MAX_SENTENCE_LENGTH - 1)\n  y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:42:31.312640Z","iopub.execute_input":"2022-04-09T05:42:31.313015Z","iopub.status.idle":"2022-04-09T05:42:31.318535Z","shell.execute_reply.started":"2022-04-09T05:42:31.312982Z","shell.execute_reply":"2022-04-09T05:42:31.317221Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"learning_rate = CustomSchedule(D_MODEL)\n\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n\n\nmodel.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy, perplexity], run_eagerly=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:42:42.363893Z","iopub.execute_input":"2022-04-09T05:42:42.364274Z","iopub.status.idle":"2022-04-09T05:42:42.384448Z","shell.execute_reply.started":"2022-04-09T05:42:42.364242Z","shell.execute_reply":"2022-04-09T05:42:42.383622Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100\n\nhistory = model.fit(dataset, epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T05:56:56.599233Z","iopub.execute_input":"2022-04-09T05:56:56.599559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}